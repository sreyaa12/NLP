# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hApRN_NVq4QDGol4LQepnMFujXbesoSh
"""

import pandas as pd
import re
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/drive/MyDrive/data science/Machine Learning/NLP/Project/email_classification.csv')
df.head()

df.shape

df.info()

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df['email'].value_counts()

text = df['email']

type(text)

text1=[]

for txt in text:
    # Lowercase the text
    txt = txt.lower()
    # Remove special characters and digits
    txt = re.sub(r'\W', ' ', txt)
    txt = re.sub(r'\d', ' ', txt)
    # Remove extra spaces
    txt = re.sub(r'\s+', ' ', txt).strip()
    text1.append(txt)  # Append the cleaned text to text1

text1

text=pd.Series(text1)

import nltk
nltk.download('punkt_tab')

from nltk.tokenize import word_tokenize
text = text.apply(lambda x:' '.join([w for w in word_tokenize(x) if len(w)>=3]))

text

# lowecase conversion and normalization(convert in to root form or cut the tail part)
from nltk.stem import SnowballStemmer
stemmer = SnowballStemmer('english')
text = text.apply(lambda x:[stemmer.stem(i.lower()) for i in word_tokenize(x)]).apply(lambda x:' '.join(x))

text

nltk.download('stopwords')

from nltk.corpus import stopwords
stop = stopwords.words('english')
text = text.apply(lambda x:[i for i in word_tokenize(x) if i not in stop]).apply(lambda x:' '.join(x))

text

from sklearn.feature_extraction.text import TfidfVectorizer
vec = TfidfVectorizer()
train_data_vec = vec.fit_transform(text)

print(train_data_vec)

train_data_vec.shape

type(train_data_vec)

y = df['label'].values

y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(train_data_vec,y,test_size=0.2,random_state=0)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(x_train,y_train)

y_pred = model.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

x_test_pred = model.predict(x_test)
test_accuracy = accuracy_score(y_test,x_test_pred)
test_accuracy

text = 'happy holidays from our team wishing you joy and prosperity this season'

import numpy as np

model.predict(vec.transform([text]))

from sklearn.naive_bayes import MultinomialNB
model1 = MultinomialNB()

model1.fit(x_train,y_train)

y_pred1 = model1.predict(x_test)
y_pred1

from sklearn.metrics import accuracy_score,confusion_matrix
accuracy_score(y_test,y_pred1)

#bar chart

plt.figure(figsize=(10,5))
sns.barplot(x=df['label'].value_counts().index,y=df['label'].value_counts())
plt.show()

conf_matrix = confusion_matrix(y_test, y_pred)

#Heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['ham', 'spam'], yticklabels=['ham', 'spam'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# New prediction
sample = "your amazon account has been locked click here to verify your account information"

print("The result of sample message :  " ,model.predict(vec.transform([sample])))

#Box plot
plt.figure(figsize=(10,5))
sns.boxplot(x=df['label'],y=df['email'].str.len())
plt.show()

#lineplot

plt.figure(figsize=(10, 5))
sns.lineplot(x=df['label'], y=df['email'].str.len(), ci=None)
plt.title("Email Length by Spam/Ham Labels")
plt.xlabel("Label (Ham/Spam)")
plt.ylabel("Email Length")
plt.show()

#Horizontal bar

plt.figure(figsize=(10, 5))
plt.barh(y=df['label'].value_counts().index, width=df['label'].value_counts(), height=0.8, color=['yellow', 'blue'])
plt.title("Email Count by Spam/Ham Labels")
plt.xlabel("Email Count")
plt.ylabel("Label (Ham/Spam)")
plt.show()







